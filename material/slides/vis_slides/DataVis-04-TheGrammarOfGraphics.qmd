---
title: "Data Visualization Techniques"
author: "Venustiano Soancatl Aguilar"
email: "v.soancatl.aguilar@rug.nl"
format:
  revealjs:
    self-contained: true
---

## Content

- The grammar of graphics
- The major components of layers
- Hands on practice
- Visualizations based on the gg approach

---

## The grammar of graphics

<br>
`The grammar of graphics is about grammatical rules for creating perceivable graphs, or what we call graphics`. (Leland Wilkinson, 2005).  
<br><br>
Take the analogy: `good grammar is just the first step in creating a good sentence`.

---

## An Object-Oriented Graphics System {.smaller}

1. Specification
    a. `DATA` : a set of data operations that create variables from datasets,
    b. `TRANS` : variable transformations (e.g., rank),
    c. `SCALE` : scale transformations (e.g., log),
    d. `COORD` : a coordinate system (e.g., polar),
    e. `ELEMENT` : graphs (e.g., points) and their aesthetic attributes (e.g., color),
    f. `GUIDE` : one or more guides (axes, legends, etc.).
2. Assembly
3. Display

---

## Graphics Pipeline {.smaller}

![](./images/pipeline.png){style="margin:0; padding:0; display:block;" width="800px"}

- `Algebra`, the operations that allow us to combine variables and specify dimensions of graphs.
- `Scales` involves the representation of variables on measured dimensions.
- `Statistics` covers the functions that allow graphs to change their appearance and representation schemes.
- `Geometry` covers the creation of geometric graphs from variables.

::: aside
From The Grammar of Graphics of Leland Wilkinson.
:::

---

## A layered grammar of graphics {.smaller}

![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*2X-8H_R2kKWBY1no1p8pYA.png){fig-align="center" width="400px"}

::: aside
Hadley Wickham (2010)
:::

---

## Layers of the grammar of graphics

<br>
![](https://blog.gramener.com/wp-content/uploads/2018/11/7-layers-of-grammar-of-graphics-to-tell-powerful-data-stories-3.png)

::: aside
Source: [Grammar of Graphics: Data Stories](https://blog.gramener.com/grammar-of-graphics-data-stories/)
:::

---

## A layer is composed of

1. data and aesthetic mappings
2. a geometric object
3. a statistical transformation
4. a position adjustment

---

## 1. Data and aesthetic mapping

---

### Scales â€” Mapping Data to Aesthetic Attributes

::: {.columns}
::: {.column width="55%"}

```{r}
library(ggplot2)

df <- data.frame(
  x = 1:10,
  y = (1:10)^2,
  group = rep(c("A", "B"), each = 5)
)

ggplot(df, aes(x, y, color = group, size = y)) +
  geom_point() +
  scale_color_manual(values = c("A" = "#0072B2", "B" = "#E69F00")) +
  scale_size_continuous(range = c(2, 10)) +
  labs(
    title = "Mapping Data to Color and Size",
    x = "X Value", y = "Y Value"
  ) +
  theme_minimal(base_size = 18) +
  theme(plot.title = element_text(face = "bold", hjust = 0.5))
```
:::
::: {.column width="45%" .smaller}
What is a Scale?

    A scale defines how data values are translated into visual properties (aesthetics).

    Each aesthetic â€” color, size, shape, position, etc. â€” has a corresponding scale.

    You can customize scales to control:

        Color palettes
        Axis limits and breaks
        Legend appearance
        Transformations (e.g., log, sqrt)
:::
:::

::: aside
ðŸ’¡ Think of scales as the â€œlinkâ€ between your data and what you see.
:::

---

## Mapping data to aesthetics

- Left, `continuous` data to size and color
- Right, `discrete` data to shape and color

![](./images/data_to_aesthetics.png)

---

## Aestetic mappings

![](https://www.rforecology.com/ggplot2_image2.png){fig-align="center" width="800px"}

::: aside
Source: [A *simple* introduction to ggplot2](https://www.rforecology.com/post/a-simple-introduction-to-ggplot2/)
:::

---

## 2. Geometric objects

---

## Geometric object

![](https://www.rforecology.com/ggplot2_image3.png)

::: aside
Source: [A *simple* introduction to ggplot2](https://www.rforecology.com/post/a-simple-introduction-to-ggplot2/)
:::

---

## A sample of geometric objects {.smaller}

:::: {.columns}

::: {.column width="33%"}

**Graphical primitives**

- `geom_path()`
- `geom_rect()`
- `geom_poligon()`

**One variable**

- Discrete
  + `geom_bar()`
- Continuous
  + `geom_histogram()`
  + `geom_density()`

:::

::: {.column width="33%"}

**Two variables**

- Both continuous
  + `geom_smooth()`
  + `geom_point()`
- At least one discrete
  + `geom_count()`
  + `geom_jitter()`
- One continuous one discrete
  + `geom_boxplot()`.
  + `geom_violin()`
:::

::: {.column width="33%"}

**Three variables**

- `geom_contour()`
- `geom_tile()`
- `geom_raster()`


:::

::::

::: aside
Source: [ggplot2: Elegant Graphics for Data Analysis (3e) ](https://ggplot2-book.org/layers.html#sec-geom)
:::

---

## Aesthetics mapping in practice

```{r}
#| echo: true
library(dviz.supp)
library(forcats)
library(lubridate)

if (!requireNamespace("gt")) install.packages("gt")
library(gt)
```

```{r}
temps_long <- filter(ncdc_normals,
                station_id %in% c(
                  "USW00014819", # Chicago, IL 60638
                  #"USC00516128", # Honolulu, HI 96813
                  #"USW00027502", # Barrow, AK 99723, coldest point in the US
                  "USC00042319", # Death Valley, CA 92328 hottest point in the US
                  "USW00093107", # San Diego, CA 92145
                  #"USC00427606"  # Salt Lake City, UT 84103
                  "USW00012918" # Houston, TX 77061
                )) %>%
  mutate(location = fct_recode(factor(station_id),
                               "Chicago" = "USW00014819",
                               #"Honolulu, HI" = "USC00516128",
                               #"Barrow, AK" = "USW00027502",
                               "Death Valley" = "USC00042319",
                               "San Diego" = "USW00093107",
                               #"Salt Lake City, UT" = "USC00427606",
                               "Houston" = "USW00012918")) %>%
  mutate(location = factor(location, levels = c("Death Valley", "Houston", "San Diego", "Chicago")))

# print(head(temps_long))

head(temps_long) |> gt() %>%  
  tab_header(
    title = "Daily temperature data",
  ) %>% 
  cols_align(align = "center") 
```
::: aside
Source: [Fundamentals of Data Visualization](https://clauswilke.com/dataviz/aesthetic-mapping.html)
:::

---

## Mapping and geometry

```{.r code-line-numbers="1-6"}
p <- ggplot(temps_long, 
            aes(x = date, 
                y = temperature, 
                color = location)
            ) +
  geom_line(linewidth = 1) +
  scale_x_date(name = "month", 
               limits = c(ymd("0000-01-01"), ymd("0001-01-04")),
               breaks = c(ymd("0000-01-01"), ymd("0000-04-01"), ymd("0000-07-01"),
                          ymd("0000-10-01"), ymd("0001-01-01")),
               labels = c("Jan", "Apr", "Jul", "Oct", "Jan"), expand = c(1/366, 0)) + 
  scale_y_continuous(limits = c(19.9, 107),
                     breaks = seq(20, 100, by = 20),
                     name = "temperature (Â°F)") +
  scale_color_OkabeIto(order = c(1:3, 7), name = NULL) +
  theme_dviz_grid() +
  theme(legend.title.align = 0.5)
```

```{r}
p <- ggplot(temps_long, 
            aes(x = date, 
                y = temperature, 
                color = location)
            ) +
  geom_line(linewidth = 1) +
  scale_x_date(name = "month", 
               limits = c(ymd("0000-01-01"), ymd("0001-01-04")),
               breaks = c(ymd("0000-01-01"), ymd("0000-04-01"), ymd("0000-07-01"),
                          ymd("0000-10-01"), ymd("0001-01-01")),
               labels = c("Jan", "Apr", "Jul", "Oct", "Jan"), expand = c(1/366, 0)) + 
  scale_y_continuous(limits = c(19.9, 107),
                     breaks = seq(20, 100, by = 20),
                     name = "temperature (Â°F)") +
  scale_color_OkabeIto(order = c(1:3, 7), name = NULL) +
  theme_dviz_grid() +
  theme(legend.title.align = 0.5)
```


::: aside
Code: [Fig2_3_temperature_plot.ipynb](https://github.com/Venustiano/DataVisMaterial/blob/main/material/scripts/FDV/Fig2_3_temperature_plot.ipynb)
:::

---

## Temperature plot

```{r}
print(p)
```


---

### Seaborn and the Grammar of Graphics

```{.python code-line-numbers="5-13"}
# Create plot
fig, ax = plt.subplots(figsize=(9, 5))

# Use seaborn lineplot; pass palette by mapping
sns.lineplot(
    data=lf,
    x='date',
    y='temperature',
    hue='location',
    palette=palette_map,
    linewidth=1.5,  # similar to geom_line linewidth
    ax=ax
)

# X-axis limits and breaks (use valid years 2000-01-01 to 2001-01-04)
xmin = pd.to_datetime("2000-01-01")
```

::: aside
[Seaborn and the Grammar of Graphics](https://www.practicaldatascience.org/notebooks/class_5/week_1/2.3.1_plotting_with_seaborn.html#seaborn-and-the-grammar-of-graphics)
:::

---


## Temperature plot using `Seaborn`

```{r}
# getwd()

library(reticulate)
use_python("/opt/conda/bin/python", required = TRUE)
```

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.dates import DateFormatter, MonthLocator

lf = pd.read_csv('../../scripts/FDV/temps_long.csv')

def force_year_2000(s):
    if pd.isna(s):
        return pd.NaT
    parts = str(s).split('-')
    if len(parts) == 3:
        return pd.to_datetime(f"2000-{int(parts[1]):02d}-{int(parts[2]):02d}", errors='coerce')
    return pd.to_datetime(s, errors='coerce')

lf['date'] = lf['date'].apply(force_year_2000)

# Set plotting style to something like theme_dviz_grid
sns.set_style("whitegrid")
plt.rcParams.update({
    "axes.spines.top": False,
    "axes.spines.right": False,
    "axes.grid.which": "major",
    "grid.color": "#e9e9e9",
    "grid.linestyle": "-",
    "grid.linewidth": 0.8
})

# Okabe-Ito-ish palette (colors from the Okabe-Ito palette)
okabe_ito = [
    "#E69F00",  # orange
    "#56B4E9",  # sky blue
    "#009E73",  # bluish green
    "#F0E442",  # yellow
    "#0072B2",  # blue
    "#D55E00",  # vermillion
    "#CC79A7"   # reddish purple
]
# choose order similar to R: order = c(1:3,7) -> indices 0,1,2,6 in Python zero-based
palette_order = [okabe_ito[i] for i in [0, 1, 2, 6]]

# If you have exactly 4 locations and want those colors in that order:
locations = lf['location'].unique()
# Map the palette to the location factor levels (you may want to set explicit levels)
palette_map = {}
for i, loc in enumerate(sorted(locations)):  # use sorted or your preferred order
    palette_map[loc] = palette_order[i % len(palette_order)]

# Create plot
fig, ax = plt.subplots(figsize=(9, 5))

# Use seaborn lineplot; pass palette by mapping
sns.lineplot(
    data=lf,
    x='date',
    y='temperature',
    hue='location',
    palette=palette_map,
    linewidth=1.5,  # similar to geom_line linewidth
    ax=ax
)

# X-axis limits and breaks (use valid years 2000-01-01 to 2001-01-04)
xmin = pd.to_datetime("2000-01-01")
xmax = pd.to_datetime("2001-01-04")
ax.set_xlim(xmin, xmax)

# Place month ticks at Jan, Apr, Jul, Oct, Jan (across year boundary)
# Use MonthLocator for the specific months
month_positions = [1, 4, 7, 10, 1]  # the last 1 represents the Jan in next year
# We'll place ticks at 2000-01-01, 2000-04-01, 2000-07-01, 2000-10-01, 2001-01-01
tick_dates = pd.to_datetime([
    "2000-01-01", "2000-04-01", "2000-07-01", "2000-10-01", "2001-01-01"
])
ax.set_xticks(tick_dates)
ax.xaxis.set_major_formatter(DateFormatter('%b'))  # short month names like Jan, Apr, ...

# Y-axis limits and ticks
ax.set_ylim(19.9, 107)
ax.set_yticks(np.arange(20, 101, 20))
ax.set_ylabel("temperature (Â°F)")

# Legend formatting: remove legend title (equivalent to name = NULL) and center title alignment
leg = ax.legend(title=None, frameon=False, loc='best')
# If you want the legend placed in a specific spot, change loc

# Small layout tweaks
plt.tight_layout()
plt.show()
```

---

## Changing the geometry to `heatmap`

Preprocessing:

- Compute mean by `location & month`
- Replace `month` numbers with `names`

```{r}
library(data.table)

# ensure temps_long is a data.table
setDT(temps_long)

month_names <- c("01" = "Jan", "02" = "Feb", "03" = "Mar",   
                  "04" = "Apr", "05" = "May", "06" = "Jun",
                  "07" = "Jul", "08" = "Aug", "09" = "Sep", "10" = "Oct", "11" = "Nov", "12" = "Dec"
                )

# compute mean by location & month, then replace month numbers with names and set factor levels
mean_temps <- temps_long[, .(mean = mean(temperature, na.rm = TRUE)),
                          by = .(location, month)
                        ]
mean_temps[, month := month_names[month]             # convert numeric month -> name
          ]
mean_temps[, month := factor(month, levels = unname(month_names))  # set factor with desired order
          ]

head(mean_temps) |> gt() %>%  
  tab_header(
    title = "Mean temperature per month",
  ) %>% 
  cols_align(align = "center") 

```

---

## Aesthetics mapping and geometry

```{.r code-line-numbers="1-3"}
p <- ggplot(mean_temps, 
            aes(x = month, y = location, fill = mean)) + 
     geom_tile(width = .95, height = 0.95) +
     scale_fill_viridis_c(option = "B", begin = 0.15, end = 0.98,
                       name = "temperature (Â°F)") + 
     scale_y_discrete(name = NULL) +
     ...
```

```{r}
#| fig-width: 15
#| out-width: "80%"
p <- ggplot(mean_temps, 
            aes(x = month, y = location, fill = mean)) + 
     geom_tile(width = .95, height = 0.95) +
     scale_fill_viridis_c(option = "B", begin = 0.15, end = 0.98,
                       name = "temperature (Â°F)") + 
      scale_y_discrete(name = NULL) +
      coord_fixed(expand = FALSE) +
      theme_dviz_open() +
      theme(axis.line = element_blank(),
        axis.ticks = element_blank(),
        #axis.text.y = element_text(size = 14),
        legend.title = element_text(size = 12)
      )
print(p)
```

---

## 3. Statistical transformations

---

### Common `statistical` transformations

<br>


```{r}
library(gt)

# Build a data frame with the information
stat_table <- tibble::tribble(
  ~Name, ~Description,
  "bin", "Divide continuous range into bins, and count number of points in each",
  "boxplot", "Compute statistics necessary for boxplot",
  "contour", "Calculate contour lines",
  "density", "Compute 1d density estimate",
  "identity", "Identity transformation, f(x) = x",
  "jitter", "Jitter values by adding small random value",
  "qq", "Calculate values for quantile-quantile plot",
  "quantile", "Quantile regression",
  "smooth", "Smoothed conditional mean of y given x",
  "summary", "Aggregate values of y for given x",
  "unique", "Remove duplicated observations"
)

stat_table |> 
  gt() |> 
  tab_header(
    title = md("**ggplot2 `stat_` functions**"),
    subtitle = "Table adapted from Hadley Wickham (2016),"
  ) |> 
  fmt_markdown(columns = vars(Name, Description)) |> 
  cols_align(align = "left", columns = vars(Name, Description))

# knitr::kable(stat_table, caption = "Common ggplot2 stat_ functions")

```

---

## Contours

Plot the `blue jay` relationship between body mass and head length.

<br>

```{r}

head(blue_jays) |> gt() %>%  
  tab_header(
    title = "Blue jay dataset",
  ) %>% 
  cols_align(align = "center") 
```

---

## Contour plot, first version

```{.r code-line-numbers="1,6,7,8,"}
blue_jays_base <- ggplot(blue_jays, aes(Mass, Head)) + 
  scale_x_continuous(limits = c(57, 82), expand = c(0, 0), name = "body mass (g)") +
  scale_y_continuous(limits = c(49, 61), expand = c(0, 0), name = "head length (mm)" ) +
  theme_dviz_grid()

blue_jays_base + 
  stat_density_2d(color = "black", size = 0.4, binwidth = 0.004) +
  geom_point(color = "black", size = 1.5, alpha = 1/3)
```

```{r}
blue_jays_base <- ggplot(blue_jays, aes(Mass, Head)) + 
  scale_x_continuous(
    limits = c(57, 82),
    expand = c(0, 0),
    name = "body mass (g)") +
  scale_y_continuous(
    limits = c(49, 61),
    expand = c(0, 0),
    name = "head length (mm)"
  ) +
  theme_dviz_grid()

blue_jays_base + 
  stat_density_2d(color = "black", size = 0.4, binwidth = 0.004) +
  geom_point(color = "black", size = 1.5, alpha = 1/3)
```

---

## Apply some shading


```{r}
#| echo: true
#| out-width: "80%"

blue_jays_base + 
  stat_density_2d(aes(fill = ..level..), geom = "polygon", color = "black", size = 0.15, binwidth = 0.004) +
  geom_point(color = "black", size = 1.5, alpha = .4) +
  scale_fill_gradient(low = "grey95", high = "grey70", guide = "none")
```

::: aside
Source: [Fundamentals of Data Visualization](https://clauswilke.com/dataviz/overlapping-points.html), `Fig18_8-10_contours.ipynb`
:::

---

## Grouping  by `sex`

```{.r code-line-numbers="1-4"}
blue_jays_base + 
  aes(color = KnownSex) +
  stat_density_2d(size = 0.4, binwidth = 0.006) +
  geom_point(size = 1.5, alpha = 0.7) +
  ...
```

```{r}
blue_jays_base + 
  aes(color = KnownSex) +
  stat_density_2d(size = 0.4, binwidth = 0.006) +
  geom_point(size = 1.5, alpha = 0.7) +
  scale_color_manual(
    values = c(F = "#D55E00", M = "#0072B2"),
    breaks = c("F", "M"),
    labels = c("female birds   ", "male birds"),
    name = NULL,
    guide = guide_legend(
      direction = "horizontal",
      override.aes = list(size = 2, linetype = 0)
    )
  ) +
  theme(
    legend.position = c(1, 0),
    legend.justification = c(1, 0),
    #legend.position = "top",
    #legend.justification = "right",
    #legend.box.spacing = unit(3.5, "pt"), # distance between legend and plot
    legend.text = element_text(vjust = 0.6),
    legend.spacing.x = unit(2, "pt"),
    legend.background = element_rect(fill = "white", color = NA),
    #legend.key.width = unit(10, "pt")
    axis.ticks.length = unit(0, "pt"),
    axis.ticks = element_blank()
  )
```

---

## Bins

Common applications:

- Histograms
- Contours
- `Heatmaps`, aggregate values into grid cells to display intensity across two dimensions
- Temporal aggregation
- Large-data intensity approximation

---

## Binning in mass spectrometry data {.smaller}

:::: {.columns}

::: {.column width="40%"}

Prompt: Given a pandas dataframes with more than 200 million rows and an 'mz' column having more than 26 million unique values. How can the table be aggregated in such a way that we can create a heat map with **`mz`** on the vertical axis, **`time`** on the horizontal axis and **`intensity`** on the 'z' axis (color)?
:::

::: {.column width="60%"}

| Id | Time     | scanid | index  | intensity | mz         |
|----|----------:|--------:|--------:|------------:|-------------:|
| 1  | 0.312346  | 35     | 376857 | 9           | 1548.487069 |
| 1  | 0.312346  | 38     | 2796   | 9           | 99.330436   |
| 1  | 0.312346  | 38     | 274380 | 9           | 979.736426  |
| 1  | 0.312346  | 38     | 313091 | 9           | 1179.351225 |
| 1  | 0.312346  | 39     | 322655 | 9           | 1231.517479 |
| â€¦  | â€¦         | â€¦      | â€¦      | â€¦           | â€¦           |
| 6481 | 691.492002 | 916 | 55969  | 86          | 200.037732  |
| 6481 | 691.492002 | 916 | 74584  | 138         | 243.540075  |
| 6481 | 691.492002 | 916 | 92301  | 62          | 288.915998  |
| 6481 | 691.492002 | 916 | 218889 | 53          | 725.852351  |
| 6481 | 691.492002 | 917 | 215210 | 99          | 710.363398  |

:::

::::

::: {.aside}
**Note:**  
Data excerpt from a mass spectrometry file.  
Dataset contains **221,592,952 rows Ã— 6 columns**.
:::

---

## AI Response {.smaller}

To aggregate such a large Pandas DataFrame for creating a heatmap, you can use binning and grouping techniques to reduce the data into manageable chunks. Here's a general approach to achieve this:

<br>

```{.python}
# Step 1: Downsample or aggregate the data if necessary to avoid memory issues
# Step 2: Create a pivot table (heatmap structure) by aggregating intensity
heatmap_data = super_df.pivot_table(index=pd.cut(super_df['mz'], bins=mz_bins), 
                              columns=pd.cut(super_df['Time'], bins=time_bins), 
                              values='intensity', 
                              aggfunc='mean')  # You can change 'mean' to 'sum' if appropriate

# Step 3: Apply a logarithmic transformation to highlight minority values
# Step 4: Plot the heatmap
plt.figure(figsize=(17, 10))  # Adjust figure size as needed
sns.heatmap(heatmap_data_log, cmap='magma', norm=None,cbar_kws={'label': 'Log(Intensity)'})  
# 'magma' gives more emphasis on high values

# Step 6: Show the plot
plt.show()
```

---

## Result

![](./images/mz_vs_time_vs_intensity_heatmap.png)

---

## 4. Position adjustment

---

## Position Adjustments in `ggplot2`

```{r}
library(gt)

# Create the data
positions <- data.frame(
  Position = c("identity", "stack", "fill", "dodge", "jitter", "nudge"),
  Description = c(
    "No adjustment â€” geoms are placed exactly where data specifies.",
    "Stacks elements vertically along the y-axis.",
    "Like 'stack', but scales bars to show proportions (fills to 100%).",
    "Places overlapping objects side-by-side for comparison.",
    "Adds small random variation to reduce overplotting.",
    "Moves text or labels slightly to improve readability."
  ),
  Commonly_Used_With = c(
    "geom_point(), geom_bar()",
    "geom_bar(), geom_area()",
    "geom_bar(), geom_area()",
    "geom_bar(), geom_boxplot()",
    "geom_point()",
    "geom_text(), geom_label()"
  )
)

# Build the improved table
positions %>%
  gt() %>%
  tab_header(
    title = md("**Position Adjustments in ggplot2**")
  ) %>%
  cols_label(
    Position = md("**Position**"),
    Description = md("**Description**"),
    Commonly_Used_With = md("**Commonly Used With**")
  ) %>%
  # cols_width(
  #   Position ~ px(12),
  #   Description ~ px(62),
  #   Commonly_Used_With ~ px(26)
  # ) %>%
  opt_table_font(size = 22) %>%     # Larger, presentation-friendly font
  tab_style(
    style = cell_text(
      font = google_font("Fira Code"),
      weight = "bold",
      color = "#444444"
    ),
    locations = cells_body(columns = "Position")
  ) %>%
    tab_style(
    style = cell_text(
      font = google_font("Fira Code"),
      color = "#444444"
    ),
    locations = cells_body(columns = "Commonly_Used_With")
  ) %>%
  tab_options(
    table.width = pct(100),
    # column_labels.font.weight = "bold",
    # data_row.padding = px(10),      # More vertical spacing between rows
    # table.font.names = c("industrial", "monospace-code", "serif")
  )
```

---

### Position dodge

```{python}
import plotly.express as px

import pandas as pd
# Loading and displaying the data
lf = pd.read_csv('../../data/exergamelf2.csv')

plot = px.box(x=lf['myVars'], 
                  y=lf['normVal'], 
                  color = lf["older"]
                  )
# plot.update_traces(opacity=0.6, width=0.8);
# plot.update_layout(
#     xaxis_tickangle=45
# );

plot.show()
```

---

## Using jitter to deal with occlusion

```{r}
p_mpg_solid <- ggplot(mpg, aes(y = cty, x = displ, color = drv, fill = drv)) +
  geom_point(size = 3, shape = 21) + 
  ylab("fuel economy (mpg)") +
  xlab("displacement (l)") +
  scale_color_manual(values=c("#202020", "#E69F00", "#56B4E9"), 
                     name="drive train",
                     breaks=c("f", "r", "4"),
                     labels=c("FWD", "RWD", "4WD")) +
  scale_fill_manual(values=c("#202020", "#E69F00", "#56B4E9"), 
                     name="drive train",
                     breaks=c("f", "r", "4"),
                     labels=c("FWD", "RWD", "4WD")) +
  theme_dviz_open() +
  theme(legend.position = c(.7, .8),
        plot.margin = margin(3, 7, 3, 1.5))

stamp_bad(p_mpg_solid)
```

::: {.aside}
Source: [Fundamentals of Data Visualization](https://clauswilke.com/dataviz/overlapping-points.html), `Fig1-3_jitter.ipynb`
:::

---

## Partial transparency

```{r}
p_mpg_transp <- ggplot(mpg, aes(y = cty, x = displ, color = drv, fill = drv)) +
  geom_point(size = 3, shape = 21,alpha=0.4) + 
  ylab("fuel economy (mpg)") +
  xlab("displacement (l)") +
  scale_color_manual(values=c("#202020", "#E69F00", "#56B4E9"), 
                     name="drive train",
                     breaks=c("f", "r", "4"),
                     labels=c("FWD", "RWD", "4WD")) +
  scale_fill_manual(values=c("#20202080", "#E69F0080", "#56B4E980"), 
                     name="drive train",
                     breaks=c("f", "r", "4"),
                     labels=c("FWD", "RWD", "4WD")) +
  theme_dviz_open() +
  theme(legend.position = c(.7, .8),
        plot.margin = margin(3, 7, 3, 1.5))

p_mpg_transp
```

## Jitter

```{r}
p_mpg_jitter <- ggplot(mpg, aes(y = cty, x = displ, color = drv, fill = drv)) +
  geom_point(size = 3, shape = 21,
             position = position_jitter(width = 0.01 * diff(range(mpg$displ)),
                                        height = 0.01 * diff(range(mpg$cty)),
                                        seed = 7384)) + 
  ylab("fuel economy (mpg)") +
  xlab("displacement (l)") +
  scale_color_manual(values=c("#202020", "#E69F00", "#56B4E9"), 
                     name="drive train",
                     breaks=c("f", "r", "4"),
                     labels=c("FWD", "RWD", "4WD")) +
  scale_fill_manual(values=c("#20202080", "#E69F0080", "#56B4E980"), 
                     name="drive train",
                     breaks=c("f", "r", "4"),
                     labels=c("FWD", "RWD", "4WD")) +
  theme_dviz_open() +
  theme(legend.position = c(.7, .8),
        plot.margin = margin(3, 7, 3, 1.5))

p_mpg_jitter
```

---

### Using jitter to visualize outliers

![](./images/Jitter_boxplots.png)

::: aside
Source: [https://doi.org/10.1016/j.gaitpost.2017.12.015](https://doi.org/10.1016/j.gaitpost.2017.12.015)
:::

---

## The `facets` layer

- Faceting = splitting a dataset into subsets and drawing the `same plot design` for each subset.
- It's a declarative way to show conditional relationships: "plot `y` vs `x` for each level of variable z".
- Benefits: compares patterns across groups while keeping scales and geoms consistent.
- The row and column variables must be categorical.

---

## Violin plots example

![](./images/facets_violinplots_example.png)

::: aside
penguins.csv
:::

---

## Heatmap facets example

![](./images/facets_example.png)

::: aside
Source: [https://doi.org/10.1016/j.gaitpost.2017.12.015](https://doi.org/10.1016/j.gaitpost.2017.12.015)
:::

---

### Plotly Express â€” interactive faceting

```{python}
#| echo: true
df = px.data.tips()
fig = px.scatter(df, x="total_bill", y="tip", facet_col="sex", color="smoker",
                 title="Tip vs Bill faceted by sex")
fig.update_layout(legend_title_text="Smoker");
fig.show()
```

---

## Coodinate systems

- In the **Grammar of Graphics**, the *coordinate system* defines how data coordinates are mapped to the **2D plane** of the plot.
- It determines:
  - The *axes* (orientation and scaling)
  - The *shape* of geometric objects
  - The *relationships* between x and y aesthetics

---

## Importance of coordinate systems

- They control **how data is drawn**, not **what data** is shown.
- Changing coordinates can:
  - Flip, stretch, or transform plots
  - Reveal patterns not visible in the default Cartesian system
  - Support specialized visualizations (like polar plots)

---

## Common Coordinate Systems

```{r}

coords <- data.frame(
  Coordinate_System = c(
    "coord_cartesian()", 
    "coord_flip()", 
    "coord_fixed()", 
    "coord_polar()", 
    "coord_quickmap()", 
    "coord_trans()"
  ),
  Description = c(
    "Default Cartesian coordinates; standard x-y axes.",
    "Swaps x and y axes â€” useful for horizontal bar plots.",
    "Ensures fixed aspect ratio between x and y units.",
    "Converts Cartesian to polar coordinates (e.g., pie charts).",
    "Approximates a Mercator projection â€” great for maps.",
    "Applies a mathematical transformation to axes (e.g., log scale)."
  )
)

coords %>%
  gt() %>%
  tab_header(title = md("**Common Coordinate Systems in ggplot2**")) %>%
  cols_label(
    Coordinate_System = md("**Function**"),
    Description = md("**Description**")
  ) %>%
  tab_style(
    style = cell_text(font = google_font("Fira Code"), weight = "bold"),
    locations = cells_body(columns = "Coordinate_System")
  ) %>%
  # cols_width(
  #   Coordinate_System ~ px(180),
  #   Description ~ px(600)
  # ) %>%
  opt_table_font(size = 20)
```

---

## Example: Polar Coordinates {.smaller}

::: {.columns}

::: {.column width="60%"}

```{r}
#| fig-width: 6

# Generate synthetic daily temperature data
set.seed(123)
days <- 1:365
temp <- 10 + 10 * sin(2 * pi * days / 365) + rnorm(365, sd = 2)
climate <- data.frame(day = days, temp = temp)

ggplot(climate, aes(x = day, y = temp)) +
  geom_line(color = "#0072B2", linewidth = 0.9) +
  coord_polar(start = pi/2) +
  scale_x_continuous(
    breaks = seq(0, 365, by = 90),
    labels = c("Jan", "Apr", "Jul", "Oct", "Jan")
  ) +
  labs(
    title = "Annual Temperature Cycle",
    x = NULL, y = "Temperature (Â°C)"
  ) +
  theme_minimal(base_size = 18) +
  theme(
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    panel.grid.minor = element_blank(),
    plot.title = element_text(hjust = 0.5, face = "bold")
  )
```
:::

::: {.column width="38%"}
- Synthetic daily temperature data
- **time series** -> **circular layout**,  
- The **x-axis** (day of year) -> **angle**.  
- The **y-axis** (temperature) -> **distance from center**. 
:::
::::

::: aside
This type of visualization helps identify repeating trends â€”  
like *seasonal temperature variation* â€” in a compact, intuitive way.
:::

---

## RUG plot app

Create `facets`, `violin plots`, `tikz` using:  [![](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/Venustiano/DataVis2/HEAD?urlpath=git-pull%3Frepo%3Dhttps%3A%2F%2Fgithub.com%2FVenustiano%2FDataVisMaterial)

![](./images/rugplotapp.png)

---

## The Grammar o Graphics in python

[plotnine](https://mybinder.org/v2/gh/Venustiano/dvizpy/HEAD)

